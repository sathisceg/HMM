{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import brown\n",
    "\n",
    "import nltk\n",
    "from nltk.corpus import brown\n",
    "import numpy as np\n",
    "from collections import Counter\n",
    "from collections import defaultdict\n",
    "from math import log\n",
    "import time\n",
    "import math\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "splitting the corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "size = int(len(brown.tagged_sents(categories='news')) * 0.8)\n",
    "size\n",
    "brown_tagged_sents = brown.tagged_sents(categories='news')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_sents = brown_tagged_sents[:size]\n",
    "test_sents = brown_tagged_sents[size:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # # sentences = np.array(train_sents)\n",
    "# words = brown.tagged_words(categories='news')\n",
    "# tokens,taged = zip(*words)\n",
    "# tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tokens\n",
    "# words"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Seperating Token and tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_sents[0][1]\n",
    "token_tag_pair_train=[]\n",
    "\n",
    "for sentence in train_sents:\n",
    "#     print(sentence)\n",
    "    for ttu in sentence:\n",
    "#         print(ttu)\n",
    "        token_tag_pair_train.append(ttu)\n",
    "       \n",
    "# train_sents[0][1]\n",
    "test_sentence_token_list=[]\n",
    "test_sentence_tag_list=[]\n",
    "\n",
    "for sentence in test_sents:\n",
    "#     print(sentence)\n",
    "    line0=[]\n",
    "    line1=[]\n",
    "    for ttu in sentence:\n",
    "#         print(ttu[0],ttu[1])\n",
    "        line0.append(ttu[0])\n",
    "        line1.append(ttu[1])\n",
    "        \n",
    "    test_sentence_token_list.append(line0)    \n",
    "    test_sentence_tag_list.append(line1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "seperating token and tag for training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "token_tag_pair_train\n",
    "tokens,taged = zip(*token_tag_pair_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tokensCount = Counter(tokens)\n",
    "# tokensCount\n",
    "wordcount = Counter(tokens)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "calculating emission value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "emissionCount = defaultdict(Counter)\n",
    "\n",
    "# print(emissionCount)\n",
    "\n",
    "for token, tag in token_tag_pair_train:\n",
    "    emissionCount[token][tag]+=1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Total token in training dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "# emissionCount['disapprove']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "totaltrain = len(words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "calculating prior probability of tag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "tagPriorValue = Counter(taged)\n",
    "# print(len(tagPriorValue.values()))\n",
    "# print(tagPriorValue.values())\n",
    "for i in tagPriorValue.keys():\n",
    "    tagPriorValue[i] = tagPriorValue[i]/totaltrain"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "calculating transmission probability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "trigram = nltk.ngrams(taged,3)\n",
    "\n",
    "# tagtags=defaultdict()\n",
    "\n",
    "transmissiontrigramscount={}\n",
    "\n",
    "for i,j,k in trigram:\n",
    "    tri = (i,j,k)\n",
    "    if tri not in transmissiontrigramscount:\n",
    "           transmissiontrigramscount[tri] =0\n",
    "    transmissiontrigramscount[tri] += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "viterbi algo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "def viterbi(transition,currentword,flag):\n",
    "    \n",
    "#     print(test[num])    \n",
    "    emmission = emissionCount[currentword]    \n",
    "#     print(emmission)    \n",
    "    #totalemission count\n",
    "    \n",
    "    totaltag=len(transition)\n",
    "    \n",
    "    te =wordcount[currentword]    \n",
    "#     print(te)\n",
    "    estimate={}\n",
    "    \n",
    "    for q3,ev in emmission.items():        \n",
    "#         print(ik,ii)\n",
    "#         flag=0\n",
    "        prob=0        \n",
    "        for q1q2 in transition:\n",
    "#             print(prior[q1q2])\n",
    "#             print(transition[q1q2]/totaltag)\n",
    "#             print()            \n",
    "            findq3=list(q1q2)[-1]\n",
    "            \n",
    "            if findq3==q3:\n",
    "                \n",
    "                if flag==0:\n",
    "                    \n",
    "                    prob = math.log(ev/te)  + math.log(transition[q1q2]/(totaltag-1))\n",
    "                    flag=1\n",
    "                else:\n",
    "                    temp = transition[q1q2]/totaltag+math.log((ev/te))  + math.log((transition[q1q2]/(totaltag-1)))\n",
    "                    prob = max(temp,prob)\n",
    "            \n",
    "        estimate[q3]=prob\n",
    "    \n",
    "    return estimate\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test = ['The', 'Fulton', 'County', 'Grand', 'Jury']\n",
    "# # print(len(tagPriorValue))\n",
    "# p = viterbi(transmissiontrigramscount,'The',0)\n",
    "# print(max(prev))\n",
    "predicted_tag=[]\n",
    "\n",
    "for sentence in test_sentence_token_list:\n",
    "#     print(sentence)\n",
    "    line=[]\n",
    "    flag=0\n",
    "    for token in sentence:\n",
    "#         print(token)\n",
    "        p = viterbi(transmissiontrigramscount,token,flag)\n",
    "        flag=1\n",
    "#         print(p)\n",
    "        if(len(p)==0):\n",
    "            line.append('')\n",
    "        else:\n",
    "            line.append(max(p))        \n",
    "    predicted_tag.append(line)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test_sentence_token_list[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(predicted_tag)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test_sentence_tag_list[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [],
   "source": [
    "count=0\n",
    "totaltag=0\n",
    "i=0\n",
    "while i<len(test_sentence_tag_list):\n",
    "    y=test_sentence_tag_list[i]\n",
    "    y1=predicted_tag[i]\n",
    "    j=0\n",
    "    while j<len(y):\n",
    "        totaltag+=1\n",
    "        if(y[j]==y1[j]):\n",
    "            count+=1\n",
    "        j+=1\n",
    "    i+=1     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7792\n",
      "37.53552675947782\n"
     ]
    }
   ],
   "source": [
    "# print(count)\n",
    "print(count/totaltag*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
